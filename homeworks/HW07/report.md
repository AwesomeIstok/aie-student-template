# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

S07-hw-dataset-01.csv
Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

S07-hw-dataset-02.csv
Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

S07-hw-dataset-03.csv
Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.

S07-hw-dataset-04.csv
Высокая размерность + 2 категориальных признака + пропуски в числовых. Требует аккуратного препроцессинга.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: какие типы (числовые)
- Пропуски: нет 
- "Подлости" датасета: (разные шкалы)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: какие типы (числовые)
- Пропуски: нет
- "Подлости" датасета: (выбросы)

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: какие типы (числовые)
- Пропуски: нет
- "Подлости" датасета: (разная плотность)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: что именно делали (scaling, imputation, encoding, PCA)
- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples)
  - чем руководствовались при выборе "лучшего"
- Метрики: silhouette ( максимизация silhouette_score (для DBSCAN шумовые точки исключались при расчёте)
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (k подбирался в диапазоне)
- DBSCAN (eps, min_samples) — для датасетов 1 и 4

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN (eps=0.6, min_samples=6)
- Метрики:
  - silhouette_score = 0.382
  - davies_bouldin_score = 1.25
  - calinski_harabasz_score = 8456.1
- Коротко: DBSCAN выявил плотные группы без избыточного шума. В отличие от KMeans, не навязывает сферическую форму, что лучше соответствует структуре данных.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans (k=16)
- Метрики:
  - silhouette_score = 0.284
  - davies_bouldin_score = 0.956
  - calinski_harabasz_score = 2329.4
- Коротко: DBSCAN помечал ~8.5% точек как шум, Agglomerative показал худший silhouette

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (k=16)
- Метрики:
  - silhouette_score = 0.234
  - davies_bouldin_score = 0.966
  - calinski_harabasz_score = 2339.4
- Коротко: DBSCAN помечал ~8.5% точек как шум
- 
## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" при нелинейных формах (датасет 1 и 2), разной плотности (датасет 3) и высокой размерности (датасет 4). Он предполагает компактные, сферические кластеры одинаковой плотности.
- Наибольшее влияние оказали: масштабирование (обязательно для KMeans/DBSCAN), наличие шумовых признаков, высокая размерность и пропуски (в датасете 4).

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проведена на датасете 1: 5 запусков KMeans (n_init=10) с разными random_state.
- Результаты: средний ARI примерно 0.92, NMI примерно 0.90 высокая устойчивость.
- Вывод: устойчиво, на основании KMeans и  почти всегда находит одну и ту же структуру, несмотря на случайную инициализацию.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через средние значения признаков в каждом кластере.
- Например, в датасете 4 кластеры различались по комбинациям категориальных значениq и уровням числовых признаков.
- В датасете 1 кластеры четко разделялись по значениям f01, f02 — что подтверждалось визуализацией.

## 6. Conclusion

Silhouette_score не всегда достаточен — нужно учитывать долю шума, визуализацию и смысловую интерпретацию.
DBSCAN мощен при сложной геометрии, но чувствителен к выбору eps и может маркировать много точек как шум.
KMeans надежен при компактных кластерах, но легко «ломается» на нелинейных или разреженных данных.
Препроцессинг — ключевой этап: корректная обработка пропусков и категориальных признаков критична в unsupervised-задачах.
Устойчивость решений важна: даже при хорошем silhouette, решение может быть нестабильным без достаточного n_init или правильного метода.
PCA-визуализация помогает, но не заменяет количественную оценку.
Нет универсального метода: выбор алгоритма должен основываться на структуре данных, а не только на метриках.
