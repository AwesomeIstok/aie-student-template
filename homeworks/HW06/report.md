# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25 000 строк, 62 столбца)
- Целевая переменная: `target` ( бинарная (0 / 1), с сильным дисбалансом: класс 0 — 95.08%, класс 1 — 4.92%.)
- Признаки: что за типы (60 числовых признаков (f01–f60), все представлены в виде float64. Столбцы id и target исключены из признакового пространства. Категориальных признаков нет.)

## 2. Protocol

- Разбиение: train/test (Разбиение: train/test = 75%/25% с фиксированным random_state=42 и стратификацией по целевой переменной (stratify=y), чтобы сохранить пропорции классов в обеих выборках., `random_state`)
- Подбор: CV на train (иперпараметры подбирались на обучающей выборке с помощью кросс-валидации StratifiedKFold(n_splits=5, shuffle=True, random_state=42). Оптимизировалась метрика ROC-AUC.)
- Метрики: accuracy, F1, ROC-AUC (обусловлен задачей бинарной классификации с дисбалансом:
accuracy даёт общее представление о точности, но может вводить в заблуждение при дисбалансе;
F1 учитывает и precision, и recall, что критично для редкого класса;
ROC-AUC оценивает способность модели ранжировать объекты по вероятности принадлежности к положительному классу, не завися от порога.)

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier(strategy="most_frequent") — baseline, всегда предсказывает самый частый класс (0). Гиперпараметры не подбирались.
- LogisticRegression — линейная модель в Pipeline со StandardScaler. Подбирались: C ∈ {0.1, 1.0, 10.0}, penalty='l2', solver='lbfgs'.
- DecisionTreeClassifier — дерево решений. Подбирались: max_depth ∈ {None, 3, 5, 8}, min_samples_leaf ∈ {1, 5, 10, 20}, ccp_alpha ∈ {0.0, 0.001, 0.005, 0.01}.
- RandomForestClassifier — ансамбль из 600 деревьев. Подбирались: max_depth ∈ {None, 6, 10}, min_samples_leaf ∈ {1, 5, 10}, max_features ∈ {"sqrt", 0.5}.
- HistGradientBoostingClassifier — градиентный бустинг по гистограммам. Подбирались: learning_rate ∈ {0.03, 0.05, 0.1}, max_depth ∈ {2, 3, None}, max_leaf_nodes ∈ {15, 31, 63}.

Опционально:

- StackingClassifier — стекинг из трёх лучших моделей (LogReg, RandomForest, HistGB) с LogisticRegression в качестве мета-классификатора. Обучался без подбора гиперпараметров, использовал внутреннюю CV=5.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
Модель	                Accuracy	F1	    ROC-AUC
Dummy(most_frequent)	0.95088	  0.0000	0.5000
LogReg(scaled)	        0.96256	  0.4091	0.8400
DecisionTree	        0.96848	  0.5887	0.8280
RandomForest	        0.97024	  0.5674	0.9035
HistGradientBoosting	0.97984	  0.7429	0.9046
Stacking	            0.98160	  0.7767	0.9060

- Победитель StackingClassifier — показал наилучшие значения по всем трём метрикам, особенно по F1 и ROC-AUC, что говорит о его способности эффективно выявлять редкий класс без потери общей точности.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (Все эксперименты проводились с фиксированным random_state=42, что обеспечивает воспроизводимость. При изменении random_state метрики могут незначительно колебаться, но порядок моделей (особенно преимущество ансамблей) остаётся стабильным — это подтверждается практикой и внутренней CV) – кратко
- Ошибки: Confusion matrix для Stacking показывает высокую точность предсказания обоих классов, особенно значительное снижение false negatives по сравнению с более простыми моделями. Это критично, так как пропуск положительных случаев (target=1) часто дороже ложных срабатываний.
- Интерпретация: Permutation importance выявила топ-15 признаков. Лидер — f54 (снижение ROC-AUC на ~1.75% при перемешивании), за ним следуют f25, f58, f33, f04 и др. Большинство признаков вне топ-15 почти не влияют на качество, что говорит о том, что модель фокусируется на действительно информативных сигналах, а не на шуме.

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.
Деревья и ансамбли (особенно бустинг и стекинг) значительно превосходят линейные модели и одиночные деревья на сложных, многомерных данных.
При дисбалансе классов нельзя ориентироваться только на accuracy — F1 и ROC-AUC дают более полную картину.
Честный ML-протокол (фиксированный random_state, стратификация, CV на train, оценка только на test) критически важен для объективного сравнения моделей.
Stacking позволяет комбинировать сильные стороны разных алгоритмов и достигать состояния «лучшего из миров».
Интерпретация через permutation importance помогает понять, какие признаки реально работают, а не просто присутствуют в данных.
Даже при большом числе признаков модель может быть устойчивой, если правильно контролировать сложность и использовать ансамбли.
